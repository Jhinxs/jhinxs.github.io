[{"categories":null,"content":"暂无 ","date":"0001-01-01","objectID":"/about/aboutme/:0:0","tags":null,"title":"About Me","uri":"/about/aboutme/"},{"categories":["Windows Kernel"],"content":"主要记录下X64VT以及实现EPT Hook时的一些关键点 ","date":"2022-03-02","objectID":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:0","tags":["Kernel","VT"],"title":"Intel VT x64 EPT Hook框架的实现","uri":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"基本的VT开启 这部分和之前32位的没什么太大的区别，主要是在填写vmc字段时，需要额外填写如IA32_EFER，IA32E_MODE这种必须要填写的，还有像RDTSCP这种在新的win10上面系统上面做引发VMEXIT需要填写的，这种主要是为了兼容性考虑。 开启EPT的话需要在SECONDARY VM execution Control Field字段里面填写对应的enable ept字段，一般来讲不是太老的CPU都是支持的。 而在X64上多核处理的话，主要是使用KeGenericCallDpc来调用我们的VT初始化或者你需要的其他需要进行多核同步的过程，这个API就是让多个CPU同时以特殊的DPC例程执行我们的代码。 其他就是一些数据类型，寄存器的更改，换成64位的模式 ","date":"2022-03-02","objectID":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:1","tags":["Kernel","VT"],"title":"Intel VT x64 EPT Hook框架的实现","uri":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"EPT内存管理 EPT是intel为内存虚拟化而设计的一种硬件机制，主要是是为了实现Guest对于物理内存的访问控制 因为EPT的存在，Guest对一个地址访问时，每当访问一个物理地址，都会走EPT物理地址转化的过程，这个过程和x64下的VA-\u003ePA的转换过程类似，例如访问Guest访问某个进程物理地址，首先找到CR3，此时访问CR3中的物理地址，就会触发GPA-\u003eHPA的EPT转换过程，然后访问PML4，PDE等物理地址时，都会触发一个EPT的转换，这也是VT开启EPT后性能损耗的原因之一，关于EPT各个表项的内容可以查看参考 Intel-64-ia-32–system-programming-manual-vol-3 Chapter 28.2 EPT的构建 EPT的构建，感觉就是实现一个具体的地址转换的过程，从EPTP的构建，以及其中PML4,PDPT,PDT其中各个表项的各个字段的填写 pEptState-\u003eEptPageTable = PageTable; PageTable-\u003ePML4[0].all = 0; PageTable-\u003ePML4[0].Bits.read_access = 1; PageTable-\u003ePML4[0].Bits.write_access = 1; PageTable-\u003ePML4[0].Bits.exec_access_supervisor = 1; PageTable-\u003ePML4[0].Bits.PDPTPFN = MmGetPhysicalAddress(\u0026PageTable-\u003ePML3[0]).QuadPart \u003e\u003e 12; for (int i = 0; i \u003c VMM_EPT_PML3E_COUNT; i++) { PageTable-\u003ePML3[i].all = 0; PageTable-\u003ePML3[i].Bits.read_access = 1; PageTable-\u003ePML3[i].Bits.write_access = 1; PageTable-\u003ePML3[i].Bits.exec_access_supervisor = 1; PageTable-\u003ePML3[i].Bits.PDTPFN = MmGetPhysicalAddress(\u0026PageTable-\u003ePML2[i][0]).QuadPart \u003e\u003e 12; } 上面的代码中可以看到对各个EPT表项的构建主要是对其中的对应字段进行构建填写，RWX权限位的设置，以及下一级EPT页表的地址的取值填写，例如PML4T中的每个PML4项的PFN对应一张PDPT表,所以就在PFN处填写PDPT物理地址去除属性位后的其余部分。 构建PDE以及后面的页表时，最开始我是想以4kB为基准构建的，但是后来初始化EPT一直出错（其实是其他的代码有问题），我就采取了想hvpp，gbhv等项目的采用2MB大页的方式来构建 for (int i = 0; i \u003c VMM_EPT_PML3E_COUNT; i++) { for (int j = 0; j \u003c VMM_EPT_PML2E_COUNT; j++) { PageTable-\u003ePML2[i][j].all = 0; PageTable-\u003ePML2[i][j].Bits.ExecuteAccess = 1; PageTable-\u003ePML2[i][j].Bits.ReadAccess = 1; PageTable-\u003ePML2[i][j].Bits.WriteAccess = 1; PageTable-\u003ePML2[i][j].Bits.LargePage = 1; PageTable-\u003ePML2[i][j].Bits.PhyPagePFN = (i * VMM_EPT_PML2E_COUNT) + j; SetMemMtrrInfo(PageTable-\u003ePML2[i][j], (i * VMM_EPT_PML2E_COUNT) + j); } } 也就是说到了构建PDT表的时候，其中每一项PDE的PFN不再是PTT的地址了（正常4k的构建下每个PDE指向一张PTT），而且直接指向一张物理页，采取大页的方式的话，构建整个EPT就效率有一定提高，而且后来搜了相关的东西，大页有助于减少缺页中断，TLB缓存未命中发生的次数。 MTRR MTRR的全称是Memory Type Range Registers，意思就是说一组用来指定特定内存段的内存类型的特殊寄存器,这里所说的内存类型: 同样MTRR是否支持也看CPU，一般新一点的CPU都是支持的，操作系统启动时BIOS会通过MTRR设置对应的内存访问属性，通过设置MTRR可以提高内存的访问效率，同时如果想在物理机上运行EPT这也是不可少的一个步骤,EPT在初","date":"2022-03-02","objectID":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:2","tags":["Kernel","VT"],"title":"Intel VT x64 EPT Hook框架的实现","uri":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"SSDT 这个也没啥，就是涉及到SSDT的查找以及一些内核函数地址的查找 ULONG64* GetSSDTBase() { //先不考虑 KVAS ULONG64 lstar = __readmsr(0xC0000082); for (int i = 0; i \u003c 1024; i++) { if (*(PUCHAR)(lstar + i) == 0x4c \u0026\u0026 *(PUCHAR)(lstar + i + 2) == 0x15) { if (*(PUCHAR)(lstar + i + 7) == 0x4c \u0026\u0026 *(PUCHAR)(lstar + i + 9) == 0x1d) { if (*(PUCHAR)(lstar + i + 14) == 0xf7 \u0026\u0026 *(PUCHAR)(lstar + i + 15) == 0x43) { ULONG64 KiSystemServiceRepeat = (ULONG64)(PUCHAR)lstar + i; ULONG offset = *(ULONG*)(KiSystemServiceRepeat + 3); ULONG64 SSDTBase = KiSystemServiceRepeat + offset + 7; //7= lea r10,[nt!KeServiceDescriptorTable] return SSDTBase; } } } } return NULL; } ULONG64 GetNTAPIAddress() { int SyscallNumber = 0x002c; //NtTerminateProcess = 0x002c; ULONG64* ssdt = GetSSDTBase(); ULONG64 address = ((*(ULONG*)(*ssdt + SyscallNumber * 4)) \u003e\u003e 4) + *ssdt; return address; } 这里只是未开启内核页表隔离的情况，开启内核页表隔离lstar msr读取到的是KiSystemCall64Shadow地址，可能需要从KiSystemCall64Shadow开始往上搜了，具体没试过，来自于网上公开的方法。 整个VT框架具体的实现细节还是看代码比较好，不然字太多也打不过了。 Code:https://github.com/Jhinxs/hvcv ","date":"2022-03-02","objectID":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:3","tags":["Kernel","VT"],"title":"Intel VT x64 EPT Hook框架的实现","uri":"/intel-vt-x64-ept-hook%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows OS"],"content":"寄存器 首先是寄存器数值的宽度，除去标志寄存器和段寄存器(段寄存器长度均为96位，其中有16位的可见部分和80位的不可见部分)外，均为8个字节64位宽度，在32位平台的基础上，增加了R8~R15共8个寄存器 易变寄存器:RAX,RCX,RDX,R8-R11 非易变寄存器：RBP,RBX,RSI,RDI,R12-R15 ","date":"2021-08-21","objectID":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/:0:1","tags":["OS"],"title":"x64的一些特性","uri":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"categories":["Windows OS"],"content":"FS与GS 32位的操作系统中，FS寄存器在3环执向TEB结构体，0环指向KPCR结构体，在X64中，则是使用GS寄存器 微软提供了IA32_FS_BASE(0xC0000100)和IA32_GS_BASE MSR(0xC0000101)寄存器用于获取Base,因为如果用段描述的方式去获取Base的话，在64位的段描述符中，是没法再放入64位的地址 FS则继续给Wow64提供服务，也就是32位的应用程序 ","date":"2021-08-21","objectID":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/:0:2","tags":["OS"],"title":"x64的一些特性","uri":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"categories":["Windows OS"],"content":"内存布局与内存模型 x64下内存分配，理论可以使用2^64次大小的内存空间，但是实际操作系统设计时只用了其中的48位，x64采用了9-9-9-9-12分页，也就是PML4T分页，按照32位操作系统非PAE分页的套路，也即10-10-12分页，PDE-PTE-offset，总的内存1024x1024x4k=4Gb，其中用户和内核各使用了2GB,在x64下理论上支持，512x512x512x512x4k=256Tb，实际上windows支持16TB左右的空间 其中: 用户空间:0x00000000~00000000 — 0x000007fff~ffffffff 内核空间:0xfffff800~00000000 — 0xffffffff~ffffffff IA-32架构下主要内存模型为:Basic Flat Module(基本的平坦模型)，Protect Flat Module(受保护的平坦模式)，Multi-Segment Module(分段内存模型) Basic Flat Module(基本的平坦模型) 最为简单的一种模型，操作系统和应用程序可以访问不受限制的内存空间，没有任何的分段机制，根据inter开发手册所说，一个最简单的平坦模型，至少建立两个段描述符，一个数据，一个代码，分别指向了数据段，代码段，但是都被映射到基址为0，限长为4gb的内存空间，即便访问的地址超过了实际物理内存的最大地址，也不会报错 Protect Flat Module(受保护的平坦模式) 主要是在基本的平坦模型中，提供了内存访问保护，超出界限后会出发保护异常，同样有了特权级机制的段权限分配，也即用户模式和内核模式，这些段的基址都是从0开始，也就是说这些段在内存空间上来说都是重叠的，逻辑上划分为不同的用途 Multi-Segment Module(分段内存模型) 相较于前两种，稍稍复杂一点，这种对于不同用途的段在内存划分上也分离开来，实现真正的内存分段，对不同段，如代码段，数据段，内存访问采用seg base+offset的形式，采用了强制的硬件级的保护机制，每个应用程序可以有自己的私有段，也可以和其他程序共享，同样的，段权限检查和访问控制机制，都可以阻止如内存越界等非法访问操作 在x64中，根据inter开发手册: In 64-bit mode, segmentation is generally (but not completely) disabled, creating a flat 64-bit linear-address space. The processor treats the segment base of CS, DS, ES, SS as zero, creating a linear address that is equal to the effective address. The FS and GS segments are exceptions. These segment registers (which hold the segment base) can be used as additional base registers in linear address calculations. They facilitate addressing local data and certain operating system data structures. CS, DS, ES, SS的段基址全部为0,base全部为0，但是FS和GS除外，它们的base可以通过前面说过的MSR寄存器获得 x64中，中断描述符和TSS段描述符均变为了128位，代码段和数据段描述符依然是64位 ","date":"2021-08-21","objectID":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/:0:3","tags":["OS"],"title":"x64的一些特性","uri":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"categories":["Windows OS"],"content":"调用约定 X64的调用约定使用4寄存器的fast-call约定，整数参数在寄存器RCX,RDX,R8,R9,尽管使用了寄存器传参，但是系统还是会分配堆栈空间，而且堆栈平衡是由调用者完成 VOID x64_go(int a, int b, int c, int d) { printf(\"a:%d\\n\", a); printf(\"b:%d\\n\", b); printf(\"c:%d\\n\", c); printf(\"d:%d\\n\", d); } VOID main() { int a = 1; int b = 2; int c = 3; int d = 4; x64_go(a, b, c, d); printf(\"over\\n\"); system(\"pause\"); } 这段测试代码中，调用函数时所对应的汇编是这样的 mov dword ptr [a],1 mov dword ptr [b],2 mov dword ptr [c],3 mov dword ptr [d],4 mov r9d,dword ptr [d] mov r8d,dword ptr [c] mov edx,dword ptr [b] mov ecx,dword ptr [a] call x64_go 可以看到当我们的参数长度不超过4个字节的时候，分别使用32位的寄存器进行传参，这个是编译器做的处理，长度足够存储数据的情况下，优先使用32位寄存器，因为操作64位寄存器(如MOV指令)的指令占4个字节，多一个48前缀指令，说明操作数是64位的，而32位寄存器只需要3个字节的指令长度 然后是堆栈分配的问题，调用者在调用子函数之前，根据函数参数的总长度，分配堆栈空间，这个堆栈空间至少要能容纳Regs*8，也就是所需保存的寄存器的总长度，如果有局部变量，则需要额外分配，并且要确保，在进入函数的时候，RSP要0x10对齐，这个堆栈空间用来进入子函数后，保存这些寄存器，以免后续可能会用到这些寄存器，从而改变导致后续出现异常 如果我想调用一个4个参数的函数，大概应该就是这样 VOID x64_go2(int a, int b, int c, int d) { printf(\"a:%d\\n\", a); printf(\"b:%d\\n\", b); printf(\"c:%d\\n\", c); printf(\"d:%d\\n\", d); } test1 proc mov rcx,1 mov rdx,2 mov r8,3 mov r9,4 sub rsp,30h call x64_go2 add rsp,30h ret test1 endp 栈帧 x86函数下，一般以标志性的 push ebp,mov ebp,esp,sub esp,xxxx 三连起始,其中通过ebp被叫为帧指针，esp为栈指针，前者对应栈底，后者对应栈顶，而一般进行如局部变量访问，参数访问等，都是通过ebp来找的，例如一般情况下ebp+4是返回地址，ebp+8是第一个参数，函数堆栈图大概如下这样，从上到下地址逐渐减小 x64下使用RSP即为栈指针也为帧指针，所有的操作以RSP为基准进行，类似pop和push等可以更改RSP的操作，一般都在函数开始和尾部进行，RSP在同一个函数体内，保持不变 VOID x64_go(int a, int b, int c) { printf(\"a:%d\\n\", a); printf(\"b:%d\\n\", b); printf(\"c:%d\\n\", c); } VOID main() { int a = 1; int b = 2; int c = 3; x64_go(a, b, c); } 上面的代码，对应如下的一个过程: 至于堆栈布局，其实和x86的是类似的 VOID x64_go(ULONG64 a, ULONG64 b, ULONG64 c) { int x = 111; printf(\"a:%llx\\n\", a); printf(\"b:%llx\\n\", b); printf(\"c:%llx\\n\", c); } VOID main() { ULONG64 a = 1; ULONG64 b = 2; ULONG64 c = 3; ULONG64 d = 4; x64_go(a, b, c); system(\"pause\"); } 把核心的汇编代码抠出来，用来做堆栈结构图 sub rsp, 48h mov dword ptr [rsp+30h], 1 mov dword ptr [rsp+28h], 2 mov dword ptr [rsp+20h], 3 mov dword ptr [rsp+38h], 4 mov r8d, [rsp+20h] mov rdx, [rsp+28h] mov rcx","date":"2021-08-21","objectID":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/:0:4","tags":["OS"],"title":"x64的一些特性","uri":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"categories":["Windows OS"],"content":"X64分页机制 x64分页和32位系统下的PAE分页分页是相似的，在原有的3级页映射的基础上，多了PML4T(4级页映射表)，因为x64使用了48位的虚拟地址，根据地址转换过程中虚拟地址的对应关系，也叫做9-9-9-9-12分页 以虚拟地址0x13fb7ff98为例，此处存了一个自定义字符串,因为实际使用了48位虚拟地址，所以最终拆分的地址为0x00013fb7ff98 拆分后得到9-9-9-9-12结构为 0000 0000 0 0 0000 0010 0 0x4 1111 1110 1 0x1fd 1011 1111 1 0x17f 1111 1001 1000 0xf98 在手动查找物理地址时，要注意高于48位以及低12位清0，这些是属性和保留位，只有中间的部分12-48位为PFN页帧，除了最后的12位页面偏移，其他的都要乘以8，因为每个PDE，PTE等页目录项都是8个字节为单位 0: kd\u003e !dq 130fd1000 #130fd1000 03000001`26616867 00000000`00000000 #130fd1010 00000000`00000000 00000000`00000000 #130fd1020 00000000`00000000 00000000`00000000 #130fd1030 00000000`00000000 00000000`00000000 #130fd1040 00000000`00000000 00000000`00000000 #130fd1050 00000000`00000000 00000000`00000000 #130fd1060 00000000`00000000 00000000`00000000 #130fd1070 00000000`00000000 00800001`2f312867 0: kd\u003e !dq 00000001`26616000+0x4*8 #126616020 03100001`24a17867 00000000`00000000 #126616030 00000000`00000000 00000000`00000000 #126616040 00000000`00000000 00000000`00000000 #126616050 00000000`00000000 00000000`00000000 #126616060 00000000`00000000 00000000`00000000 #126616070 00000000`00000000 00000000`00000000 #126616080 00000000`00000000 00000000`00000000 #126616090 00000000`00000000 00000000`00000000 0: kd\u003e !dq 00000001`24a17000+0x1fd*8 #124a17fe8 05200001`24818867 00000000`00000000 #124a17ff8 00000000`00000000 006f004c`00740076 #124a18008 00650052`002e0067 00720075`006f0073 #124a18018 00220073`00650063 00720065`00760020 #124a18028 006e006f`00690073 002e0036`0022003d #124a18038 00360037`002e0031 0032002e`00310030 #124a18048 00320037`00300033 00720070`00200022 #124a18058 00730065`0063006f 00410072`006f0073 0: kd\u003e !dq 00000001`24818000+0x17f*8 #124818bf8 9e100000`bdfba005 b2300000`71cf0005 #124818c08 b2400000`73af1005 95600001`2e45d005 #124818c18 a0000001`308d6005 b2500000`71df2005 #124818c28 b2600001`064f3005 b2700000`734f4005 #124818c38 b2800001`2f2f5005 b2900000`70bf6005 #124818c48 b2a00000`b8ff7005 b2b00000`b9ff8005 #124818c58 b2c00001`227f9005 b2d00001`2defa005 #124818c68 b2e","date":"2021-08-21","objectID":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/:0:5","tags":["OS"],"title":"x64的一些特性","uri":"/x64%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"categories":["Windows Kernel"],"content":" Intel VT-x是Intel芯片用于支持硬件虚拟化的一种技术，个人理解是在传统的操作系统之上，创建专用于虚拟化开发者的特权级环境，这种权限甚至高于操作系统的环境，也就是常说的Hypervisor层，同样的，新的环境也会引入一些新的特权指令等新的功能。在设计架构上和SVM类似，分为VMM和VMGUEST两种角色，分别处于VMX-ROOT和VMX-NO ROOT模式下 对于虚拟机来说，Hypervisor是完全透明的，当Guest客户机发生vmexit事件后会陷入到Hypervisor，此时控制权完全交与Hypervisor，而Hypervisor同样可以通过vmlaunch运行虚拟机，或者在处理完vmexit事件后，通过vmresume指令，继续运行虚拟机 ","date":"2021-06-02","objectID":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:0","tags":["Kernel","VT"],"title":"Intel VT-x mini VT 框架的实现","uri":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"VT框架实现流程 本代码用于学习研究，运行于32位操作系统之上，在代码实现VT的时候，主要是需要遵循Intel开发手册的标准，我这里实现的时候，大概是以下的流程: 判断当前CPU是否支持VT技术，通过执行cpuid指令，获取返回信息并判断对应的标志位，这是硬件层面的要求 读取MSR_IA32_FEATURE_CONTROL MSR寄存器对应标志位，用于判断在BIOS配置中是否开启了VT 检查并设置CR4 VMXE标志位 分配4K对齐的内存，用于vmx操作，这块区域按照白皮书的定义一般叫做VMXON region 初始化VMXON region区域，主要是写入一个VMCS版本号，这个版本号通过读取 IA32_MSR_VMX_BASIC MSR寄存器获得 执行VMXON,并检查EFLAGE.CF位是否置0，判断是否执行成功 分配4K对齐的内存，用于逻辑处理器也即虚拟机的操作区域，叫做VMCS region 调用vmclear指令，将VMCS区域设置为清除状态，也即区域初始化 调用vmptrld指令，激活VMCS 为host以及guest分配内存空间 填充VMCS区域，这是最重要也是最复杂的一步 通过vmlaunch运行虚拟机 ","date":"2021-06-02","objectID":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:1","tags":["Kernel","VT"],"title":"Intel VT-x mini VT 框架的实现","uri":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"代码部分 这个代码写的也是一波三折，蓝屏N次，也是各种坑，虽然可以有参考代码，但实际上有很多因素，遇到比如像保存现场代码的优化，多核处理等等诸多问题 首先是开启VT的前期，检测阶段，首先就是通过CPUID指令，这个指令执行前，需要将EAX寄存器置为1，返回值会存在ECX寄存器中，这里CPUID置1是Intel的要求，如果EAX中是其他值，返回的信息也是不同的，只是在这里用作CPU VTZ支持检测，EAX需要置1 get_cpuid_info proc,_para:dword pushad mov eax,1H cpuid mov esi,_para mov [esi],ecx popad ret get_cpuid_info endp 然后是读取IA32_FEATURE_CONTROL MSR寄存器,如果在bios启用VT则bit1，bit2或者两者都必须为1，bit1和bit2主要用于设置是否处于SMX Mode（安全扩展模式）下，这里一般检测bit2就可以了 ULONG64 msr = __readmsr(MSR_IA32_FEATURE_CONTROL); if (!(msr \u0026 4)) //4.VT 指令是否被锁定 { DbgPrint(\"MSR_IA32_FEATURE_CONTROL VMXON Locked \\n\"); return STATUS_UNSUCCESSFUL; } 检测并设置CR4.VMXE也就是bit13位，在VMXON和VMXOFF之间不许再修改此位 set_cr4(X86_CR4_VMXE); //3.设置CR4.VMXE cr4 = get_cr4(); if ((cr4 \u0026 X86_CR4_VMXE) != X86_CR4_VMXE) { DbgPrint(\"CR4_VMXE set Error \\n\"); return STATUS_UNSUCCESSFUL; } 分配VMXON Region区域，读取MSR寄存器，获取VMCS标识并用其初始化VMXON Region，白皮书中说设置前31位，这里需要注意分配非分页内存，然后就可以通过VMXON进入虚拟机模式了，这里首先要获取VMXON Region区域的物理地址，作为参数传递给VMXON，执行完VMXON后需要验证Eflags寄存器的CF位和ZF是否为0，0表示开启成功(参考 Intel-64-ia-32–system-programming-manual-vol-3 Chapter 24.1) vmx_on proc,LowPart:dword,HighPart:dword push HighPart push LowPart vmxon qword ptr [esp] add esp,8 ret vmx_on endp vmx_basic_msr = __readmsr(MSR_IA32_VMX_BASIC); //获取vmcs identifier VMX_Region = ExAllocatePoolWithTag(NonPagedPool, 4096, 'vmx'); RtlZeroMemory(VMX_Region, 4096); *(ULONG*)VMX_Region = (vmx_basic_msr \u0026 0x7ffffff); VMXONRegion_PA = MmGetPhysicalAddress(VMX_Region); vmx_on(VMXONRegion_PA.LowPart,VMXONRegion_PA.HighPart); 前期检测的过程基本完了，接下来就是分配内存了，首先是分配VMCS Region,这块区域是最核心的，可以看为是虚拟化逻辑处理器做各种操作所需要的内存空间，VMCS Region中存在各种域，是需要手动指定填充的，同样需要为Host分配一块内存，用于guest发生vmexit回到host所需要的内存空间，同样分配内存4k对齐以及非分页，在驱动卸载时要释放这几块内存区域，在VMCS Region分配完后，需要调用vmclear以及vmptrld指令，用于初始化和激活VMCS Region VMXCS_Region = ExAllocatePoolWithTag(NonPagedPool, 4096,'vmcs'); DbgPrint(\"VMXCS_Region: %x\\n\", VMXCS_Region); RtlZeroMemory(VMXCS_Region, 4096); vmx_basic_msr = __readmsr(MSR_IA32_VMX_BASIC); *(ULONG*)VMXCS_Region = (vmx_basic_msr \u0026 0x7ffffff); VMCSRegion","date":"2021-06-02","objectID":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:2","tags":["Kernel","VT"],"title":"Intel VT-x mini VT 框架的实现","uri":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Windows Kernel"],"content":"扩展 1.VMEXIT导致GDT Limit发生改变，使用ARK工具查看GDT相关信息时出发BSoD 这个是在看zhouhe的VT教程看到的，至于原因，白皮书说,VMEXIT时会加载一些host的CR寄存器,msr寄存器,加载GDTR和IDTR时，limit会从3ff变为ffff: 在驱动加载,开启VT前可以保存一份GDTR，驱动卸载，关闭VT后恢复即可 2.VM第一次初始化运行，驱动继续执行的问题,就是说我们运行vmlaunch之后，进入虚拟机里，后续的驱动代码时不会执行的，卡死的状态，所以我们要构造一个上下文环境，在vmlaunch之后，我们的驱动代码可以正常执行完毕： VTenable_before(); StartVMXCS(); VTenable_after(); 在VMCS初始化填写前后，构造两个函数，我这里汇编实现： VTenable_before proc cli mov DriverEAX,eax mov DriverECX,ecx mov DriverEDX,edx mov DriverEBX,ebx mov DriverESP,esp mov DriverEBP,ebp mov DriverESI,esi mov DriverEDI,edi pushfd pop DriverEFL sti ret VTenable_before endp 之前保存现场，之后恢复现场，第一次进入VM时，就会跳转到我们的vmx_GuestReturn代码执行，而这个vmx_GuestReturn功能就是调用VTenable_after()，确保驱动正常执行完毕 vmx_vmwrite(VMCS_GUSTAREA_RIP, (ULONG)vmx_GuestReturn); 3.多核问题 看雪小宝来了说过这个问题，就是说我们VT的开启，肯定是以CPU为基准的，单核那就在这个核上开启VT就行，但如果是多核的情况下，不可能仅在个别核上开启VT，那必然时蓝屏啊，所以需要扩展至多核兼容，比如分配各种内存时，需要每个核都分配，同样在执行VT代码的时候，每个核都要执行一边才行 for (int i = 0; i \u003c KeNumberProcessors; i++) { KeSetSystemAffinityThread((KAFFINITY)(1 \u003c\u003c i)); VT_Enable(); KeRevertToUserAffinityThread(); DbgPrint(\"stop vt on cpu [%d]...\\n\", i); } 具体API的使用以及用途,参考MSDN文档即可 Code: https://github.com/Jhinxs/x32_VT Reference: https://github.com/zzhouhe/VT_Learn/tree/master/MinimalVT https://bbs.pediy.com/thread-211973.htm https://github.com/haidragon/newbluepill «new blue pill:深入理解硬件虚拟机» «Intel 64-ia-32–system-programming-manual-vol-3» ","date":"2021-06-02","objectID":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:3","tags":["Kernel","VT"],"title":"Intel VT-x mini VT 框架的实现","uri":"/intel-vt-x-mini-vt-%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/"}]