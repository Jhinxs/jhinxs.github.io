<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>机器学习小记 - Jhin&#39;s Story</title><meta name="Description" content="Jhinxs"><meta property="og:title" content="机器学习小记" />
<meta property="og:description" content="监督学习 MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]],processEscapes: true,processEnvironments: true,skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; },extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] }}});MathJax.Hub.Queue(function() {// Fix  tags after MathJax finishes running. This is a// hack to overcome a shortcoming of Markdown. Discussion at// https://github.com/mojombo/jekyll/issues/199var all = MathJax.Hub.getAllJax(), i;for(i = 0; i 监督学习从已有的数据集来建议一种模式（函数），来预测新的值，而数据是已有label的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" /><meta property="og:image" content="https://jhinxs.com/images/jhin.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-14T14:02:16+08:00" />
<meta property="article:modified_time" content="2023-04-14T14:02:16+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jhinxs.com/images/jhin.png"/>

<meta name="twitter:title" content="机器学习小记"/>
<meta name="twitter:description" content="监督学习 MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]],processEscapes: true,processEnvironments: true,skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; },extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] }}});MathJax.Hub.Queue(function() {// Fix  tags after MathJax finishes running. This is a// hack to overcome a shortcoming of Markdown. Discussion at// https://github.com/mojombo/jekyll/issues/199var all = MathJax.Hub.getAllJax(), i;for(i = 0; i 监督学习从已有的数据集来建议一种模式（函数），来预测新的值，而数据是已有label的。"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" /><link rel="prev" href="https://jhinxs.com/%E5%AE%89%E5%85%A8%E6%9E%B6%E6%9E%84-%E9%9B%B6%E4%BF%A1%E4%BB%BB%E5%88%9D%E8%AF%86/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "机器学习小记",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/jhinxs.com\/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0\/"
        },"image": ["https:\/\/jhinxs.com\/jhin.png"],"genre": "posts","keywords": "Machine Learning, Math","wordcount":  815 ,
        "url": "https:\/\/jhinxs.com\/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0\/","datePublished": "2023-04-14T14:02:16+08:00","dateModified": "2023-04-14T14:02:16+08:00","license": "jhinxs story","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/jhinxs.com\/jhin.png"},"author": {
                "@type": "Person",
                "name": "jhinxs"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Jhin&#39;s Story"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Jhinxs</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="https://github.com/Jhinxs" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Jhin&#39;s Story"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>Jhinxs</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="https://github.com/Jhinxs" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">机器学习小记</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>jhinxs</a></span>&nbsp;<span class="post-category">included in <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6ai/"><i class="far fa-folder fa-fw"></i>机器学习，数学，AI</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2023-04-14">2023-04-14</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;815 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#线性回归">线性回归</a>
      <ul>
        <li><a href="#代价函数cost-function">代价函数（Cost Function）</a></li>
        <li><a href="#梯度下降">梯度下降</a></li>
        <li><a href="#多元线性回归">多元线性回归</a></li>
        <li><a href="#特征缩放">特征缩放</a></li>
        <li><a href="#线性回归实验代码">线性回归实验代码</a></li>
      </ul>
    </li>
    <li><a href="#逻辑回归">逻辑回归</a>
      <ul>
        <li><a href="#逻辑函数">逻辑函数</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="监督学习">监督学习</h1>
<script src="https://fastly.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<p>监督学习从已有的数据集来建议一种模式（函数），来预测新的值，而数据是已有label的。</p>
<p>回归：从无限多的可能的数字来预测一个值<br>
<a href="/images/assets/post8/huigui.PNG" rel=""><img src="/images/assets/post8/huigui.PNG" width="100%"/></a></p>
<p>分类：只需对数据做类别预测，且是有限的<br>
<a href="/images/assets/post8/fenlei.PNG" rel=""><img src="/images/assets/post8/fenlei.PNG" width="100%"/></a></p>
<h1 id="无监督学习">无监督学习</h1>
<p>使用的数据集没用提前的属性，使用算法分析未标签化数据集，发现隐藏的模式或数据分组，无需人工干预，并形成聚类
聚类：<br>
<a href="/images/assets/post8/julei.PNG" rel=""><img src="/images/assets/post8/julei.PNG" width="100%"/></a></p>
<h2 id="线性回归">线性回归</h2>
<p>使用一条线（函数）尽可能的拟合所有的数据<br>
<a href="/images/assets/post8/xianxinghuigui.PNG" rel=""><img src="/images/assets/post8/xianxinghuigui.PNG" width="100%"/></a></p>
<h3 id="代价函数cost-function">代价函数（Cost Function）</h3>
<p>存在这样的函数关系：$$f_{w,b}(x^{(i)})=wx^{(i)}+b$$<br>
用$y^{(i)}$表示为真实值，则应使$f_{w,b}(x^{(i)})$(预测值)尽可能等于$y^{(i)}$ <br>
通常使用右边这个式子来代表误差：$(f_{w,b}(x^{(i)})-y^{(i)})^{2}$。<br>
最终整个数据集得到的误差和的值会很大，所以尽可能的减小数字大小，在此基础上计算均方误差，并在除以2，就得到了代价函数:
$$J(w,b)=\frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$</p>
<p><a href="/images/assets/post8/cost3d.PNG" rel=""><img src="/images/assets/post8/cost3d.PNG" width="100%"/></a></p>
<h3 id="梯度下降">梯度下降</h3>
<p>通过代价函数可以得到，最终误差取决于w,b两个值，所以需要一点一点的修正w,b的值,这也是梯度下降算法：
$$ w=w-\alpha\frac{\partial J(w,b)}{\partial w}$$
$$ b=b-\alpha\frac{\partial J(w,b)}{\partial b}$$
这里$\alpha$叫做学习率，也决定了梯度下降的步幅，学习率过小则需要很多步才能收敛，过大则有可能起到反作用，$\frac{\partial J(w,b)}{\partial w}$为J(w,b)对w求偏导，也即斜率，斜率可正可负，正则最终w会越来越小，反而则越来越大,b同理。<br>
<a href="/images/assets/post8/gra1.PNG" rel=""><img src="/images/assets/post8/gra1.PNG" width="100%"/></a><br>
<a href="/images/assets/post8/gra2.PNG" rel=""><img src="/images/assets/post8/gra2.PNG" width="100%"/></a><br>
梯度下降算法涉及到的求导过程：
根据符合复合函数的求导法则,$f'(g(x))=f'(g(x))g'(x)$,先对w求偏导:
$$J'(w,b)=\frac{1}{2m} \sum\limits_{i = 0}^{m-1}\frac{\partial}{\partial w} ((f_{w,b}(x^{(i)}) - y^{(i)})^2) \tag{1}$$ 
$$J'(w,b)=\frac{1}{2m} \sum\limits_{i = 0}^{m-1}2 (f_{w,b}(x^{(i)}) - y^{(i)}) \frac{\partial}{\partial w} (wx^{(i)}+b - y^{(i)}) \tag{2}$$
$$J'(w,b)=\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \frac{\partial}{\partial w} (wx^{(i)}+b - y^{(i)}) \tag{3}$$
其中后半部分，对w求导，其余看作常数，对b求导，其余看作常数，得到：
$$\frac{\partial}{\partial w}(wx^{(i)}+b - y^{(i)}) =x^{(i)} \tag{4}$$
$$\frac{\partial}{\partial b}(wx^{(i)}+b - y^{(i)}) = 1 \tag{5}$$
带入（3）则得到：
$$\frac{\partial}{\partial w}J(w,b)=\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) x^{(i)}$$
$$\frac{\partial}{\partial b}J(w,b)=\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) $$
使用python实现上述算法：<br>
代价函数</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">
<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
   
    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">f_wb</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost</span> <span class="o">+</span> <span class="p">(</span><span class="n">f_wb</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">cost</span>

    <span class="k">return</span> <span class="n">total_cost</span>

</code></pre></td></tr></table>
</div>
</div><p>计算梯度：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">compute_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span> 
    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    
    <span class="n">dj_dw</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dj_db</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>  
        <span class="n">f_wb</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span> 
        <span class="n">dj_dw_i</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_wb</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> 
        <span class="n">dj_db_i</span> <span class="o">=</span> <span class="n">f_wb</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> 
        <span class="n">dj_db</span> <span class="o">+=</span> <span class="n">dj_db_i</span>
        <span class="n">dj_dw</span> <span class="o">+=</span> <span class="n">dj_dw_i</span> 
    <span class="n">dj_dw</span> <span class="o">=</span> <span class="n">dj_dw</span> <span class="o">/</span> <span class="n">m</span>        
    <span class="n">dj_db</span> <span class="o">=</span> <span class="n">dj_db</span> <span class="o">/</span> <span class="n">m</span>        
        
    <span class="k">return</span> <span class="n">dj_dw</span><span class="p">,</span> <span class="n">dj_db</span>

</code></pre></td></tr></table>
</div>
</div><p>其中： dj_dw=$\frac{\partial}{\partial w}J(w,b)$,dj_db=$\frac{\partial}{\partial b}J(w,b)$</p>
<h3 id="多元线性回归">多元线性回归</h3>
<p>多元线性回归，样例具有多个特征$x^{(i)}$，结果预测受多个因素的影响：<br>
<a href="/images/assets/post8/multihouse.PNG" rel=""><img src="/images/assets/post8/multihouse.PNG" width="100%"/></a><br>
可表示为：
$$ f_{w,b}(\mathbf{x}) =  w_0x_0 + w_1x_1 +&hellip; + w_{n-1}x_{n-1} + b $$
用向量点积表示为：
$$f_{w,b}(x)=\vec w \cdot \vec x+b$$
多元代价函数可表示为:
$$J(w,b)=\frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})^2$$ 
则梯度下降算法变为：<br>
$$ w_1=w_1-\alpha\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)}) x_1^{(i)}$$
$$ \cdot\cdot\cdot $$
$$ \cdot\cdot\cdot $$
$$ \cdot\cdot\cdot $$
$$ w_n=w_n-\alpha\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)}) x_n^{(i)}$$
由于b为常数，则：
$$ b=b-\alpha\frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})$$
其中$f_{\vec w,b}(\vec x^{(i)})$为预测值，$y^{(i)}$为目标值。</p>
<h3 id="特征缩放">特征缩放</h3>
<p>归一化(normalization)与标准化(Standardization)是指特征缩放的过程，常见的方式：
min-max 归一化：$$x'=\frac{x-min(x)}{max(x)-min(x)}$$
Mean normalization: $$x'=\frac{x-\overline x}{max(x)-min(x)}$$
Standardization：$$x'=\frac{x-\overline x}{\sigma}$$
$\overline x$为平均数，$\sigma$为标准差<br>
问题：为什么需要进行特征缩放？<br>
$f(x) = w_1 * 1000 + w_2 * 0.5$,
其中$w_1$的变动对于整个结果的影响过大，$w_2$的影响被稀释,最终代价函数受$w_1$的影响更大，从而影响整个梯度下降。</p>
<h3 id="线性回归实验代码">线性回归实验代码</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># -*- coding:utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">myload_data</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&#34;data/ex1data1.txt&#34;</span><span class="p">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s2">&#34;,&#34;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span>

<span class="k">def</span> <span class="nf">costfunction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">f_x</span><span class="o">=</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">b</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_x</span><span class="o">-</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

    <span class="n">total_cost</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="n">cost_sum</span>
    <span class="k">return</span> <span class="n">total_cost</span>
<span class="k">def</span> <span class="nf">gradientdescent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dj_dw</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">dj_db</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
       <span class="n">tmpjb</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="o">-</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
       <span class="n">dj_db</span> <span class="o">+=</span> <span class="n">tmpjb</span>
       <span class="n">tmpjw</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="o">-</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
       <span class="n">dj_dw</span> <span class="o">+=</span><span class="n">tmpjw</span>
    
    <span class="n">dj_dw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">dj_dw</span>
    <span class="n">dj_db</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">dj_db</span>
    <span class="k">return</span> <span class="n">dj_dw</span><span class="p">,</span><span class="n">dj_db</span>
<span class="k">def</span> <span class="nf">Learning</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w_init</span><span class="p">,</span><span class="n">b_init</span><span class="p">,</span><span class="n">costfunction</span><span class="p">,</span><span class="n">gradientdescent</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">num_iters</span><span class="p">):</span>

    <span class="n">m</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">temp_j</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">temp_w</span><span class="o">=</span><span class="p">[]</span> 
    <span class="n">w</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">w_init</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">b_init</span>  
    <span class="n">iters_list</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">iters_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">dj_dw</span><span class="p">,</span><span class="n">dj_db</span> <span class="o">=</span> <span class="n">gradientdescent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">-</span><span class="n">alpha</span><span class="o">*</span><span class="n">dj_dw</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">-</span><span class="n">alpha</span><span class="o">*</span><span class="n">dj_db</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">100000</span><span class="p">:</span>
            <span class="n">cost</span> <span class="o">=</span><span class="n">costfunction</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
            <span class="n">temp_j</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">temp_j</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">5</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">abs_tol</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">)</span><span class="o">&amp;</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">abs_tol</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">)</span><span class="o">&amp;</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span><span class="n">abs_tol</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">)):</span>
                     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">-</span><span class="mi">3</span><span class="si">:</span><span class="s2">4</span><span class="si">}</span><span class="s2">: Cost </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">])</span><span class="si">:</span><span class="s2">1.8f</span><span class="si">}</span><span class="s2">   &#34;</span><span class="p">)</span>
                     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="si">:</span><span class="s2">4</span><span class="si">}</span><span class="s2">: Cost </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">])</span><span class="si">:</span><span class="s2">1.8f</span><span class="si">}</span><span class="s2">   &#34;</span><span class="p">)</span>
                     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="si">:</span><span class="s2">4</span><span class="si">}</span><span class="s2">: Cost </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span><span class="si">:</span><span class="s2">1.8f</span><span class="si">}</span><span class="s2">   &#34;</span><span class="p">)</span>
                     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:Found Cost </span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="s2">1.8f</span><span class="si">}</span><span class="s2">   &#34;</span><span class="p">)</span>
                     <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">%</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_iters</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">temp_w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">4</span><span class="si">}</span><span class="s2">: Cost </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">temp_j</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s2">1.8f</span><span class="si">}</span><span class="s2">   &#34;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iters_list</span><span class="p">,</span><span class="n">temp_j</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s2">&#34;r&#34;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Cost vs. iterations&#34;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cost J(w,b)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;iterations&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span>  <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">temp_j</span><span class="p">,</span> <span class="n">temp_w</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
   
    <span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">myload_data</span><span class="p">()</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of x_train is:&#39;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of y_train is: &#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Number of training examples (m):&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
    <span class="n">initial_w</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">initial_b</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">iterations</span> <span class="o">=</span> <span class="mi">9999</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
    
    <span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">Learning</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">initial_w</span><span class="p">,</span><span class="n">initial_b</span><span class="p">,</span><span class="n">costfunction</span><span class="p">,</span><span class="n">gradientdescent</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">iterations</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;w,b found by gradient descent:&#34;</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">x_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span>

        <span class="n">predict1</span> <span class="o">=</span> <span class="mf">3.5</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;For population = 35,000, we predict a profit of $</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">predict1</span><span class="o">*</span><span class="mi">10000</span><span class="p">))</span>

    <span class="n">predict2</span> <span class="o">=</span> <span class="mf">7.0</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;For population = 70,000, we predict a profit of $</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">predict2</span><span class="o">*</span><span class="mi">10000</span><span class="p">))</span>    

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">predicted</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s2">&#34;b&#34;</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Profits vs. Population per city&#34;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Profit in $10,000&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Population of City in 10,000s&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="逻辑回归">逻辑回归</h2>
<h3 id="逻辑函数">逻辑函数</h3>
<p>对于分类问题，结果y的计算值为0或者为1，对于线性回归来讲，会产生过多的值，并且会小于0或者大于1，所以线性回归不适合这种情况。<br>
<a href="/images/assets/post8/logistic.PNG" rel=""><img src="/images/assets/post8/logistic.PNG" width="100%"/></a><br>
g(z)也即y的结果始终在0~1区间，逻辑回归公式：
$$g(z)=\frac{1}{1+e^{(-z)}} $$
该函数可以看成是，在给定w,b前提下，对于输入x得到y等于1的概率大小，也可以这样表示：$f(x)=P(y=1|x;w,b)$</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2023-04-14</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" data-title="机器学习小记" data-via="realDonaldTrump" data-hashtags="Machine Learning,Math"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" data-hashtag="Machine Learning"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" data-title="机器学习小记"><i class="fab fa-hacker-news fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" data-title="机器学习小记"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://jhinxs.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/" data-title="机器学习小记"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/machine-learning/">Machine Learning</a>,&nbsp;<a href="/tags/math/">Math</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/%E5%AE%89%E5%85%A8%E6%9E%B6%E6%9E%84-%E9%9B%B6%E4%BF%A1%E4%BB%BB%E5%88%9D%E8%AF%86/" class="prev" rel="prev" title="安全架构-零信任初识"><i class="fas fa-angle-left fa-fw"></i>安全架构-零信任初识</a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">jhinxs</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">Jhinxs Story</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
